name: NHL Data Pipeline

on:
  push:
    branches: [ main, master ]
    paths:
      - 'scripts/**'
      - 'data/nhl/**'
      - 'requirements.txt'
      - 'main.py'
      - '.github/workflows/nhl-pipeline.yml'
  workflow_dispatch: {}

# Needed only if you plan to commit back to the repo in this job.
permissions:
  contents: write

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      # Make your secrets available to Python via os.getenv(...)
      ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
      NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pipeline
        run: |
          mkdir -p outputs
          python main.py
        # If your scripts write CSVs elsewhere, copy them into outputs/ so they're captured.
        # Example:
        # run: |
        #   python main.py
        #   mkdir -p outputs
        #   cp *.csv outputs/ || true

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nhl-outputs
          path: |
            outputs/**
            *.csv
          if-no-files-found: warn
          retention-days: 7

      # Optional: commit generated CSVs back to the repo (requires contents: write).
      # - name: Commit outputs
      #   if: success()
      #   run: |
      #     git config user.name "github-actions[bot]"
      #     git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
      #     mkdir -p outputs
      #     git add outputs/*.csv || true
      #     git commit -m "CI: update outputs [skip ci]" || echo "Nothing to commit"
      #     git push
